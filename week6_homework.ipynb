{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda install -y nomkl > tmp.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo\n",
    "* https://github.com/Lasagne/Recipes/tree/master/modelzoo\n",
    "* More models within the community\n",
    "* Pick model, copy init, download weights\n",
    "* Here we proceed with vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg16.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copyright: see http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "\n",
    "\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_3'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_3'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_3'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(\n",
    "        net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ostrich, Struthio camelus\n"
     ]
    }
   ],
   "source": [
    "#classes' names are stored here\n",
    "classes = pickle.load(open('classes.pkl'))\n",
    "#for example, 10th class is ostrich:\n",
    "print classes[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to implement two functions in the cell below.\n",
    "\n",
    "Preprocess function should take the image with shape (w, h, 3) and transform it into a tensor with shape (1, 3, 224, 224). Without this transformation, vgg19 won't be able to digest input image. \n",
    "Additionally, your preprocessing function have to rearrange channels RGB -> BGR and subtract mean values from every channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123])\n",
    "IMAGE_W = 224\n",
    "\n",
    "def preprocess(img):\n",
    "    img = img[:, :, ::-1].astype('float')\n",
    "    for i in xrange(3):\n",
    "        img[:, :, i] -= MEAN_VALUES[i]    \n",
    "    #convert from [w,h,3 to 1,3,w,h]\n",
    "    img = np.transpose(img, (2, 0, 1))[None]\n",
    "    return img\n",
    "\n",
    "def deprocess(img):\n",
    "    img = img.reshape(img.shape[1:]).transpose((1, 2, 0))\n",
    "    for i in xrange(3):\n",
    "        img[:,:, i] += MEAN_VALUES[i]\n",
    "    return img[:, :, :: -1].astype(np.uint8)\n",
    "\n",
    "img = (np.random.rand(IMAGE_W, IMAGE_W, 3) * 256).astype(np.uint8)\n",
    "\n",
    "print np.linalg.norm(deprocess(preprocess(img)) - img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, the number above will be small, because deprocess function is the inverse of preprocess function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vgg16.pkl') as f:\n",
    "    weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(net['prob'], weights['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "#output = lasagne.layers.get_output(net['prob'], input_image)\n",
    "#prob = theano.function([input_image], output)\n",
    "\n",
    "output = lasagne.layers.get_output(net['fc6'], input_image,deterministic=True)\n",
    "fc6_output = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Давайте проверим, что загруженная сеть работает. Для этого мы скормим ей картину альбатроса и проверим, что она правильно его распознаёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imread('sample_images/albatross.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "p = prob(preprocess(img))\n",
    "\n",
    "labels = p.ravel().argsort()[-1:-6:-1]\n",
    "print 'top-5 classes are:'\n",
    "for l in labels:\n",
    "    print '%3f\\t%s' % (p.ravel()[l], classes[l].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand-quest: Dogs Vs Cats\n",
    "* original competition\n",
    "* https://www.kaggle.com/c/dogs-vs-cats\n",
    "* 25k JPEG images of various size, 2 classes (guess what)\n",
    "\n",
    "### Your main objective\n",
    "* In this seminar your goal is to fine-tune a pre-trained model to distinguish between the two rivaling animals\n",
    "* The first step is to just reuse some network layer as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/d61lupw909hc785/dogs_vs_cats.train.zip?dl=1 -O data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for starters\n",
    "* Train sklearn model, evaluate validation accuracy (should be >80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract features from images\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "#this may be a tedious process. If so, store the results in some pickle and re-use them.\n",
    "for fname in tqdm(os.listdir('train/')):\n",
    "    y = fname.startswith(\"cat\")\n",
    "    img = imread(\"train/\"+fname)\n",
    "    img = preprocess(imresize(img,(IMAGE_W,IMAGE_W)))\n",
    "    features = fc6_output(img)\n",
    "    Y.append(y)\n",
    "    X.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving features:\n",
    "save, load = False, True\n",
    "if save:\n",
    "    with open('fc6_output_and_targets.pickle', 'w') as f:\n",
    "        pickle.dump([X, Y], f)\n",
    "if load:\n",
    "    with open('fc6_output_and_targets.pickle') as f:\n",
    "        X, Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.concatenate(X) #stack all [1xfeature] matrices into one. \n",
    "assert X.ndim==2\n",
    "#WARNING! the concatenate works for [1xN] matrices. If you have other format, stack them yourself.\n",
    "\n",
    "#crop if we ended prematurely\n",
    "Y = Y[:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marat/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 1)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = int(0.1*X.shape[0]),\\\n",
    "                                                  random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load our dakka__\n",
    "![img](https://s-media-cache-ak0.pinimg.com/564x/80/a1/81/80a1817a928744a934a7d32e7c03b242.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, criterion='entropy', oob_score=True)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAGyCAYAAACbT6GSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nInFFwSciInHl/wNEdNZfLKjHxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc449ec9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_val,prediction)\n",
    "s = roc_auc_score(Y_val, prediction)\n",
    "a = accuracy_score(Y_val, prediction)\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC = %.3lf \\n Acc = %.3lf' % (s, a))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Main quest\n",
    "\n",
    "* Get the score improved!\n",
    "\n",
    "No methods are illegal: ensembling, data augmentation, NN hacks. \n",
    "Just don't let test data slip into training.\n",
    "\n",
    "The main requirement is that you implement the NN fine-tuning recipe:\n",
    "### Split the raw image data\n",
    "  * please do train/validation/test instead of just train/test\n",
    "  * reasonable but not optimal split is 20k/2.5k/2.5k or 15k/5k/5k\n",
    "### Choose which vgg layers are you going to use\n",
    "  * Anything but for prob is okay\n",
    "  * Do not forget that vgg16 uses dropout\n",
    "### Build a few layers on top of chosen \"neck\" layers.\n",
    "  * a good idea is to just stack more layers inside the same network\n",
    "  * alternative: stack on top of get_output\n",
    "### Train the newly added layers for some iterations\n",
    "  * you can selectively train some weights by only sending them to your optimizer\n",
    "      * `lasagne.updates.mysupermegaoptimizer(loss, only_those_weights_i_wanna_train)`\n",
    "  * selecting all weights from the head but not below the neck:\n",
    "      * `all_params = lasagne.layers.get_all_params(new_output_layer_or_layers,trainable=True)`\n",
    "      * `old_params= lasagne.layers.get_all_params(neck_layers,trainable=True)`\n",
    "      * `new_params = [w for w in all_params if w not in old_params]`\n",
    "  * it's cruicial to monitor the network performance at this and following steps\n",
    "### Fine-tune the network body\n",
    "  * probably a good idea to SAVE your new network weights now 'cuz it's easy to mess things up.\n",
    "  * Moreover, saving weights periodically is a no-nonsense idea\n",
    "  * even more cruicial to monitor validation performance\n",
    "  * main network body may need a separate, much lower learning rate\n",
    "      * since updates are dictionaries, one can just compute union\n",
    "      * `updates = {}`\n",
    "      * `updates.update(lasagne.updates.how_i_optimize_old_weights())`\n",
    "      * `updates.update(lasagne.updates.how_i_optimize_old_weights())`\n",
    "      * make sure they do not have overlapping keys. Otherwise, earlier one will be forgotten.\n",
    "      * `assert len(updates) == len(old_updates) + len(new_updates)`\n",
    "### PROFIT!!!\n",
    "  * Evaluate the final score\n",
    "  * Submit to kaggle\n",
    "      * competition page https://www.kaggle.com/c/dogs-vs-cats\n",
    "      * get test data https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "  \n",
    "## Some ways to get bonus points\n",
    "* explore other networks from the model zoo\n",
    "* play with architecture\n",
    "* 85%/90%/93%/95%/97% kaggle score (screen pls).\n",
    "* data augmentation, prediction-time data augmentation\n",
    "* use any more advanced fine-tuning technique you know/read anywhere\n",
    "* ml hacks that benefit the final score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Creating new architecture from VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_nn = {k:v for (k, v) in net.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del custom_nn['fc6_dropout']\n",
    "del custom_nn['fc7']\n",
    "del custom_nn['fc7_dropout']\n",
    "del custom_nn['fc8']\n",
    "del custom_nn['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_nn['fc7'] = DenseLayer(custom_nn['fc6'], num_units=1024)\n",
    "custom_nn['fc8'] = DenseLayer(custom_nn['fc7'], num_units=2)\n",
    "custom_nn['prob'] = NonlinearityLayer(custom_nn['fc8'], softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setting pretrained weights to VGG-part and random weights to new part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(custom_nn['fc6'], weights['param values'][:28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_params = lasagne.layers.get_all_params(custom_nn['prob'],trainable=True)\n",
    "old_params = lasagne.layers.get_all_params(custom_nn['fc6'],trainable=True)\n",
    "new_params = [w for w in all_params if w not in old_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "custom_nn['fc7'].get_params()[0].set_value(np.random.normal(size = (4096, 1000)))\n",
    "custom_nn['fc7'].get_params()[1].set_value(np.zeros(1000))\n",
    "custom_nn['fc8'].get_params()[0].set_value(np.random.normal(size = (1000, 2)))\n",
    "custom_nn['fc8'].get_params()[1].set_value(np.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lasagne.layers.get_all_param_values(custom_nn['prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "output = lasagne.layers.get_output(custom_nn['prob'], input_image)\n",
    "prob = theano.function([input_image], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_y = T.vector('target Y', dtype = 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(output, target_y).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(output, target_y).mean()\n",
    "update_head = lasagne.updates.adam(loss, new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head_train_fun = theano.function([input_image, target_y], [loss, accuracy], updates = update_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_fun = theano.function([input_image, target_y], accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3222/5000 [03:33<04:15,  6.96it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for fname in tqdm(os.listdir('train/')[:5000]):\n",
    "    y = fname.startswith(\"cat\")\n",
    "    img = imread(\"train/\"+fname)\n",
    "    img = preprocess(imresize(img,(IMAGE_W,IMAGE_W)))\n",
    "    Y.append(y)\n",
    "    X.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batchsize):\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    batches = X.shape[0] // batchsize\n",
    "    for i in range(batches):\n",
    "        excerpt = idx[i*batchsize : (i+1)*batchsize]\n",
    "        yield X[excerpt], y[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Bad input argument to theano function with name \"<ipython-input-36-a6bb29fdafed>:1\" at index 0 (0-based)', 'Wrong number of dimensions: expected 4, got 2 with shape (100, 4096).')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-28710824eb3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhead_train_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marat/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    787\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marat/anaconda2/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    176\u001b[0m             raise TypeError(\"Wrong number of dimensions: expected %s,\"\n\u001b[1;32m    177\u001b[0m                             \" got %s with shape %s.\" % (self.ndim, data.ndim,\n\u001b[0;32m--> 178\u001b[0;31m                                                         data.shape))\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Bad input argument to theano function with name \"<ipython-input-36-a6bb29fdafed>:1\" at index 0 (0-based)', 'Wrong number of dimensions: expected 4, got 2 with shape (100, 4096).')"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(np.array(X_train), np.array(Y_train),batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= head_train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, Y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
